{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5413080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "\n",
    "# import jupyternotify\n",
    "import pylab as pl\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "import shutil\n",
    "\n",
    "# ip = get_ipython()\n",
    "# ip.register_magics(jupyternotify.JupyterNotifyMagics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        os.system('git add .; git commit -m \"Working Post Submission: testing\";git push --force origin HEAD:main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a91f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "os.system('gcloud compute instances delete --zone=europe-west3-c --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "os.system('gcloud compute instances delete --zone=asia-south1-c --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "os.system('gcloud compute instances delete --zone=us-west1-b --quiet $(gcloud compute instances list --format=\"value(name)\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09e25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [ 'globaln_12cls', 'globaln_8cls','globaln_2cls']\n",
    "\n",
    "\n",
    "\n",
    "# config_list = ['cre_setup_2_scale_1_node_info']\n",
    "\n",
    "# config_list2 = ['global_12cls',\\\n",
    "#                 'local_12cls',\\\n",
    "#                'global_3cls',\\\n",
    "#                'global_4cls',\\\n",
    "#                'global_6cls',\\\n",
    "#                'global_8cls',\\\n",
    "#                'global_2cls',\\\n",
    "#                'local_3cls',\\\n",
    "#                'local_4cls',\\\n",
    "#                'local_6cls',\\\n",
    "#                'local_8cls',\\\n",
    "#                'local_2cls']\n",
    "# config_list2 = ['local_2cls']\n",
    "\n",
    "\n",
    "config_list = config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45293342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['globaln_12cls', 'globaln_8cls', 'globaln_2cls']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d197d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 1\n",
      "9 1\n",
      "10 1\n",
      "11 1\n",
      "12 1\n",
      "13 1\n",
      "14 1\n",
      "15 1\n",
      "16 2\n",
      "17 2\n",
      "18 2\n",
      "19 2\n",
      "20 2\n",
      "21 2\n",
      "22 2\n",
      "23 2\n",
      "24 3\n",
      "25 3\n",
      "26 3\n",
      "27 3\n",
      "28 3\n",
      "29 3\n",
      "30 3\n",
      "31 3\n",
      "32 -1\n",
      "33 -1\n",
      "34 -1\n",
      "35 -1\n",
      "36 -1\n",
      "37 -1\n",
      "38 -1\n",
      "39 -1\n",
      "40 4\n",
      "41 4\n",
      "42 4\n",
      "43 4\n",
      "44 4\n",
      "45 4\n",
      "46 4\n",
      "47 4\n",
      "48 5\n",
      "49 5\n",
      "50 5\n",
      "51 5\n",
      "52 5\n",
      "53 5\n",
      "54 5\n",
      "55 5\n",
      "56 6\n",
      "57 6\n",
      "58 6\n",
      "59 6\n",
      "60 6\n",
      "61 6\n",
      "62 6\n",
      "63 6\n",
      "64 7\n",
      "65 7\n",
      "66 7\n",
      "67 7\n",
      "68 7\n",
      "69 7\n",
      "70 7\n",
      "71 7\n",
      "72 -1\n",
      "73 -1\n",
      "74 -1\n",
      "75 -1\n",
      "76 -1\n",
      "77 -1\n",
      "78 -1\n",
      "79 -1\n",
      "80 8\n",
      "81 8\n",
      "82 8\n",
      "83 8\n",
      "84 8\n",
      "85 8\n",
      "86 8\n",
      "87 8\n",
      "88 9\n",
      "89 9\n",
      "90 9\n",
      "91 9\n",
      "92 9\n",
      "93 9\n",
      "94 9\n",
      "95 9\n",
      "96 10\n",
      "97 10\n",
      "98 10\n",
      "99 10\n",
      "100 10\n",
      "101 10\n",
      "102 10\n",
      "103 10\n",
      "104 11\n",
      "105 11\n",
      "106 11\n",
      "107 11\n",
      "108 11\n",
      "109 11\n",
      "110 11\n",
      "111 11\n",
      "112 -1\n",
      "113 -1\n",
      "114 -1\n",
      "115 -1\n",
      "116 -1\n",
      "117 -1\n",
      "118 -1\n",
      "119 -1\n",
      "0 us-west1-b\n",
      "1 us-west1-b\n",
      "2 us-west1-b\n",
      "3 us-west1-b\n",
      "4 europe-west3-c\n",
      "5 europe-west3-c\n",
      "6 europe-west3-c\n",
      "7 europe-west3-c\n",
      "8 asia-south1-c\n",
      "9 asia-south1-c\n",
      "10 asia-south1-c\n",
      "11 asia-south1-c\n",
      "0 0  'us-west1-b'\n",
      "1 1  'us-west1-b'\n",
      "2 2  'us-west1-b'\n",
      "3 3  'us-west1-b'\n",
      "4 4  'us-west1-b'\n",
      "5 5  'us-west1-b'\n",
      "6 6  'us-west1-b'\n",
      "7 7  'us-west1-b'\n",
      "8 8  'us-west1-b'\n",
      "9 9  'us-west1-b'\n",
      "10 10  'us-west1-b'\n",
      "11 11  'us-west1-b'\n",
      "12 12  'us-west1-b'\n",
      "13 13  'us-west1-b'\n",
      "14 14  'us-west1-b'\n",
      "15 15  'us-west1-b'\n",
      "16 16  'us-west1-b'\n",
      "17 17  'us-west1-b'\n",
      "18 18  'us-west1-b'\n",
      "19 19  'us-west1-b'\n",
      "20 20  'us-west1-b'\n",
      "21 21  'us-west1-b'\n",
      "22 22  'us-west1-b'\n",
      "23 23  'us-west1-b'\n",
      "24 24  'us-west1-b'\n",
      "25 25  'us-west1-b'\n",
      "26 26  'us-west1-b'\n",
      "27 27  'us-west1-b'\n",
      "28 28  'us-west1-b'\n",
      "29 29  'us-west1-b'\n",
      "30 30  'us-west1-b'\n",
      "31 31  'us-west1-b'\n",
      "32 32  'us-west1-b'\n",
      "33 33  'us-west1-b'\n",
      "34 34  'us-west1-b'\n",
      "35 35  'us-west1-b'\n",
      "36 36  'us-west1-b'\n",
      "37 37  'us-west1-b'\n",
      "38 38  'us-west1-b'\n",
      "39 39  'us-west1-b'\n",
      "40 40  'europe-west3-c'\n",
      "41 41  'europe-west3-c'\n",
      "42 42  'europe-west3-c'\n",
      "43 43  'europe-west3-c'\n",
      "44 44  'europe-west3-c'\n",
      "45 45  'europe-west3-c'\n",
      "46 46  'europe-west3-c'\n",
      "47 47  'europe-west3-c'\n",
      "48 48  'europe-west3-c'\n",
      "49 49  'europe-west3-c'\n",
      "50 50  'europe-west3-c'\n",
      "51 51  'europe-west3-c'\n",
      "52 52  'europe-west3-c'\n",
      "53 53  'europe-west3-c'\n",
      "54 54  'europe-west3-c'\n",
      "55 55  'europe-west3-c'\n",
      "56 56  'europe-west3-c'\n",
      "57 57  'europe-west3-c'\n",
      "58 58  'europe-west3-c'\n",
      "59 59  'europe-west3-c'\n",
      "60 60  'europe-west3-c'\n",
      "61 61  'europe-west3-c'\n",
      "62 62  'europe-west3-c'\n",
      "63 63  'europe-west3-c'\n",
      "64 64  'europe-west3-c'\n",
      "65 65  'europe-west3-c'\n",
      "66 66  'europe-west3-c'\n",
      "67 67  'europe-west3-c'\n",
      "68 68  'europe-west3-c'\n",
      "69 69  'europe-west3-c'\n",
      "70 70  'europe-west3-c'\n",
      "71 71  'europe-west3-c'\n",
      "72 72  'europe-west3-c'\n",
      "73 73  'europe-west3-c'\n",
      "74 74  'europe-west3-c'\n",
      "75 75  'europe-west3-c'\n",
      "76 76  'europe-west3-c'\n",
      "77 77  'europe-west3-c'\n",
      "78 78  'europe-west3-c'\n",
      "79 79  'europe-west3-c'\n",
      "80 80  'asia-south1-c'\n",
      "81 81  'asia-south1-c'\n",
      "82 82  'asia-south1-c'\n",
      "83 83  'asia-south1-c'\n",
      "84 84  'asia-south1-c'\n",
      "85 85  'asia-south1-c'\n",
      "86 86  'asia-south1-c'\n",
      "87 87  'asia-south1-c'\n",
      "88 88  'asia-south1-c'\n",
      "89 89  'asia-south1-c'\n",
      "90 90  'asia-south1-c'\n",
      "91 91  'asia-south1-c'\n",
      "92 92  'asia-south1-c'\n",
      "93 93  'asia-south1-c'\n",
      "94 94  'asia-south1-c'\n",
      "95 95  'asia-south1-c'\n",
      "96 96  'asia-south1-c'\n",
      "97 97  'asia-south1-c'\n",
      "98 98  'asia-south1-c'\n",
      "99 99  'asia-south1-c'\n",
      "100 100  'asia-south1-c'\n",
      "101 101  'asia-south1-c'\n",
      "102 102  'asia-south1-c'\n",
      "103 103  'asia-south1-c'\n",
      "104 104  'asia-south1-c'\n",
      "105 105  'asia-south1-c'\n",
      "106 106  'asia-south1-c'\n",
      "107 107  'asia-south1-c'\n",
      "108 108  'asia-south1-c'\n",
      "109 109  'asia-south1-c'\n",
      "110 110  'asia-south1-c'\n",
      "111 111  'asia-south1-c'\n",
      "112 112  'asia-south1-c'\n",
      "113 113  'asia-south1-c'\n",
      "114 114  'asia-south1-c'\n",
      "115 115  'asia-south1-c'\n",
      "116 116  'asia-south1-c'\n",
      "117 117  'asia-south1-c'\n",
      "118 118  'asia-south1-c'\n",
      "119 119  'asia-south1-c'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-018' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-033' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-041' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-025' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-024' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-020' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-035' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-013' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-016' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-012' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-001' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-002' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-008' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-011' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-017' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-003' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-009' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-037' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-039' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-055' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-036' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-007' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-015' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-034' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-046' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-030' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-019' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-021' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-044' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-058' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-029' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-047' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-023' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-010' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-043' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-028' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-027' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-032' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-038' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-031' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-006' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-000' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-048' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-004' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-014' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-005' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-051' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-050' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-022' already exists\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/instances/resdb-026' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-059' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-040' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-049' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-042' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-054' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-057' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-060' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-053' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-052' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-056' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-045' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-062' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-066' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-073' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-071' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-069' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-067' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-063' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-068' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-065' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-064' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-084' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-078' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-107' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-116' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-089' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-093' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-061' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-095' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-087' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-075' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-076' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-080' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-106' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-092' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-085' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-077' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-088' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-098' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-074' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-108' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-094' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-097' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-105' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-111' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-109' already exists\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-070' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-086' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-103' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-096' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-099' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-101' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-104' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-091' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-110' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-079' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-118' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/europe-west3-c/instances/resdb-072' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-119' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-100' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-112' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-090' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-102' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-081' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-082' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-113' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-114' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-115' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-083' already exists\n",
      "\n",
      "ERROR: (gcloud.compute.instances.create) Could not fetch resource:\n",
      " - The resource 'projects/ucr-ursa-major-lesani-lab/zones/asia-south1-c/instances/resdb-117' already exists\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  7001 10.138.0.116\n",
      "test:  7002 10.138.15.202\n",
      "test:  7003 10.138.0.127\n",
      "test:  7004 10.138.0.81\n",
      "test:  7005 10.138.15.199\n",
      "test:  7006 10.138.0.52\n",
      "test:  7007 10.138.0.88\n",
      "test:  7008 10.138.0.34\n",
      "test:  7009 10.156.0.86\n",
      "test:  7010 10.156.15.193\n",
      "test:  7011 10.156.0.113\n",
      "test:  7012 10.156.15.197\n",
      "test:  7013 10.156.0.112\n",
      "test:  7014 10.156.0.120\n",
      "test:  7015 10.156.0.127\n",
      "test:  7016 10.156.15.204\n",
      "test:  7017 10.160.15.196\n",
      "test:  7018 10.160.0.32\n",
      "test:  7019 10.160.15.204\n",
      "test:  7020 10.160.15.202\n",
      "test:  7021 10.160.15.200\n",
      "test:  7022 10.160.15.199\n",
      "test:  7023 10.160.0.102\n",
      "test:  7024 10.160.0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for tejas: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a Gradle Daemon, 2 incompatible and 1 stopped Daemons could not be reused, use --status for details\n",
      "\n",
      "> Task :compileJava\n",
      "\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Some input files use unchecked or unsafe operations.\n",
      "Note: Recompile with -Xlint:unchecked for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Task :jar\n",
      "> Task :installDist\n",
      "\n",
      "BUILD SUCCESSFUL in 12s\n",
      "3 actionable tasks: 3 executed\n"
     ]
    }
   ],
   "source": [
    "for cfig in config_list:    \n",
    "    try:\n",
    "        \n",
    "        if os.path.exists('node_info.csv'):\n",
    "            os.remove('node_info.csv')\n",
    "\n",
    "        os.system('cp node_setup/'+cfig+'.csv node_info.csv')\n",
    "\n",
    "\n",
    "        df =pd.read_csv('node_info.csv')\n",
    "\n",
    "        node_info_dict = df.to_dict()\n",
    "\n",
    "        node_info_dict\n",
    "\n",
    "        total_count = 0\n",
    "\n",
    "        for key in node_info_dict['ServerOrClientregion'].keys():\n",
    "            if node_info_dict['ServerOrClientregion'][key] ==0:\n",
    "                total_count = total_count + 1\n",
    "\n",
    "        total_count\n",
    "\n",
    "        replica_count = 0\n",
    "\n",
    "        for key in node_info_dict['cluster_id'].keys():\n",
    "            if node_info_dict['cluster_id'][key] ==0:\n",
    "                replica_count = replica_count + 1\n",
    "\n",
    "\n",
    "        \n",
    "        cluster_count = 0\n",
    "        \n",
    "        for key in node_info_dict['cluster_id']:\n",
    "            print(key, node_info_dict['cluster_id'][key])\n",
    "            if node_info_dict['cluster_id'][key] > cluster_count:\n",
    "                cluster_count = node_info_dict['cluster_id'][key]\n",
    "                \n",
    "        cluster_count = cluster_count + 1\n",
    "        \n",
    "        n_clusters = cluster_count\n",
    "\n",
    "        nclients = 0\n",
    "\n",
    "        for i in node_info_dict['ServerOrClientregion']:\n",
    "        #     print(node_info_dict['ServerOrClientregion'][i])\n",
    "            if node_info_dict['ServerOrClientregion'][i] == 1:\n",
    "                nclients = nclients + 1\n",
    "        nclients\n",
    "\n",
    "        clusters_tracked = []\n",
    "        cluster_regions_tracked = []\n",
    "\n",
    "        for key in node_info_dict['region']:\n",
    "            if int(node_info_dict['cluster_id'][key]) not in clusters_tracked and int(node_info_dict['cluster_id'][key]) >=0:\n",
    "                clusters_tracked.append(int(node_info_dict['cluster_id'][key]))\n",
    "                cluster_regions_tracked.append(node_info_dict['region'][key].strip().replace('\"', '')[1:-1])\n",
    "\n",
    "\n",
    "        cluster_regions_tracked     \n",
    "\n",
    "        cluster_regions_tracked, clusters_tracked\n",
    "\n",
    "\n",
    "        regions = cluster_regions_tracked\n",
    "\n",
    "\n",
    "\n",
    "        n_regions = len(regions)\n",
    "\n",
    "        for i,k in enumerate(regions):\n",
    "            print(i,k)\n",
    "\n",
    "        for item, idx in enumerate(node_info_dict['region'].keys()):\n",
    "            print(item, idx, node_info_dict['region'][item])\n",
    "\n",
    "        lines  = []\n",
    "\n",
    "\n",
    "        for idx, key in enumerate( node_info_dict['region'].keys()):\n",
    "\n",
    "            line = 'gcloud compute instances create resdb-'+f\"{idx:03}\"+' --project=ucr-ursa-major-lesani-lab --zone='+node_info_dict['region'][key].strip()[1:-1]+' --machine-type=e2-standard-2 --network-interface=network-tier=PREMIUM,stack-type=IPV4_ONLY,subnet=default --can-ip-forward --maintenance-policy=MIGRATE --provisioning-model=STANDARD --service-account=961693926925-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --tags=http-server,https-server --create-disk=auto-delete=yes,boot=yes,device-name=instance-3,image=projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20230831,mode=rw,size=10,type=projects/ucr-ursa-major-lesani-lab/zones/us-west1-b/diskTypes/pd-balanced --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --labels=goog-ec-src=vm_add-gcloud --reservation-affinity=any'\n",
    "            lines.append(line)\n",
    "\n",
    "        with open('launch_cloud_instances.sh', 'w') as f:\n",
    "            for item in lines:\n",
    "                f.write(str(item) + '\\n')\n",
    "\n",
    "\n",
    "        len(lines), node_info_dict['region'][key].strip()[1:-1]\n",
    "\n",
    "\n",
    "        def run_command(command):\n",
    "            subprocess.call(command, shell=True)\n",
    "\n",
    "        commands = lines\n",
    "\n",
    "        # Create a ThreadPoolExecutor or ProcessPoolExecutor, depending on your needs\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=60) as executor:\n",
    "            # Submit each command to the executor for parallel execution\n",
    "            futures = [executor.submit(run_command, command) for command in commands]\n",
    "\n",
    "            # Wait for all tasks to complete\n",
    "            concurrent.futures.wait(futures)\n",
    "\n",
    "        time.sleep(180)\n",
    "        \n",
    "\n",
    "        # os.system('sh launch_cloud_instances.sh')\n",
    "\n",
    "        for folder in os.listdir('.'):\n",
    "            if 'config' in folder and folder!='config' and 'zip' not in folder and '.' not in folder:\n",
    "                shutil.rmtree(folder)\n",
    "\n",
    "\n",
    "        instance_type = 'e2-small'\n",
    "\n",
    "\n",
    "        redirect = '>'\n",
    "\n",
    "        os.system('gcloud compute instances list  --format=\"value(networkInterfaces[0].networkIP)\" '+\\\n",
    "                  redirect+' all_internal_ips')\n",
    "\n",
    "\n",
    "\n",
    "        os.system('gcloud compute instances list --format=\"value(networkInterfaces[0].networkIP)\" '+\\\n",
    "              redirect+' all_external_ips')\n",
    "\n",
    "        with open('all_internal_ips') as f:\n",
    "            ipList = f.read().splitlines()\n",
    "        ipList = [x for x in ipList if x!='None']\n",
    "\n",
    "        ipList, len(ipList)\n",
    "\n",
    "        new_server_only_ips= []\n",
    "        new_client_only_ips= []\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(total_count + nclients):\n",
    "            if node_info_dict['ServerOrClientregion'][i] ==0:\n",
    "                new_server_only_ips = new_server_only_ips + [ipList[i]]\n",
    "            else:\n",
    "                new_client_only_ips = new_client_only_ips + [ipList[i]]\n",
    "\n",
    "\n",
    "\n",
    "        # new_server_only_ips= []\n",
    "        # new_client_only_ips= []\n",
    "\n",
    "\n",
    "        # current_region_total = 0\n",
    "        # for i in range(n_regions):\n",
    "        #     print(current_region_total,current_region_total+ clusters_per_region_map[i] *replica_count)\n",
    "        #     new_server_only_ips = new_server_only_ips + ipList[current_region_total:current_region_total+ clusters_per_region_map[i] *replica_count]\n",
    "\n",
    "        #     new_client_only_ips = new_client_only_ips + ipList[current_region_total+ clusters_per_region_map[i] *replica_count:\n",
    "        #                                                       current_region_total+ clusters_per_region_map[i] *(replica_count+1)]\n",
    "\n",
    "\n",
    "        #     current_region_total = current_region_total + clusters_per_region_map[i] *replica_count +  clusters_per_region_map[i]\n",
    "\n",
    "        new_server_only_ips, len(new_server_only_ips)\n",
    "\n",
    "        new_client_only_ips, len(new_client_only_ips) \n",
    "\n",
    "        # ipList = new_server_only_ips + new_client_only_ips\n",
    "\n",
    "        # ipList, len(ipList)\n",
    "\n",
    "        nclients = 0\n",
    "        nservers = 0\n",
    "        count = 0\n",
    "\n",
    "        clusterIpMap = {}\n",
    "\n",
    "\n",
    "        for i in node_info_dict['ServerOrClientregion']:\n",
    "        #     print(node_info_dict['ServerOrClientregion'][i])\n",
    "\n",
    "            if node_info_dict['ServerOrClientregion'][i] == 0:\n",
    "                clusterIpMap[nservers] = ipList[count]\n",
    "                nservers = nservers + 1\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "        nclients = 0\n",
    "        nservers = 0\n",
    "        count = 0\n",
    "\n",
    "        for i in node_info_dict['ServerOrClientregion']:\n",
    "        #     print(node_info_dict['ServerOrClientregion'][i])\n",
    "\n",
    "            if node_info_dict['ServerOrClientregion'][i] == 1:\n",
    "                print('test: ', 7001+nclients, ipList[count])\n",
    "                clusterIpMap[7001+nclients] = ipList[count]\n",
    "                nclients = nclients + 1\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "        clusterIpMap\n",
    "\n",
    "        # clusterIpMap = {}\n",
    "\n",
    "        # for i in range(len(ipList)):\n",
    "        #     clusterIpMap[i] = ipList[i]\n",
    "\n",
    "\n",
    "        # for i in range(nclients):\n",
    "\n",
    "        #     clusterIpMap[7001+i] = ipList[-(nclients-i)]\n",
    "\n",
    "        clusterPortMap1 = {}\n",
    "        clusterPortMap2 = {}\n",
    "\n",
    "        for i in range(len(ipList) - nclients):\n",
    "\n",
    "            clusterPortMap1[i] = str(10000)\n",
    "\n",
    "        for i in range(len(ipList) - nclients):\n",
    "            clusterPortMap2[i] = str(20000)\n",
    "\n",
    "        # clusterPortMap1[7003] = '11400'\n",
    "        # clusterPortMap2[7003] = '11410'\n",
    "\n",
    "\n",
    "\n",
    "        temp = 11900\n",
    "\n",
    "        for i in range(nclients):\n",
    "\n",
    "            clusterPortMap1[7001+i] = str(10000)\n",
    "            clusterPortMap2[7001+i] = str(20000)\n",
    "\n",
    "        clusterPortMap1, clusterPortMap2\n",
    "\n",
    "        os.system('echo 3108 | sudo -S ./gradlew installDist')\n",
    "\n",
    "        for i in range(total_count):\n",
    "            os.system('./runscripts/smartrun.sh bftsmart.tom.util.RSAKeyPairGenerator '+str(i)+' 1024')\n",
    "\n",
    "\n",
    "\n",
    "        os.system('./runscripts/smartrun.sh bftsmart.tom.util.RSAKeyPairGenerator '+str(7002)+' 1024')\n",
    "        os.system('./runscripts/smartrun.sh bftsmart.tom.util.RSAKeyPairGenerator '+str(7001)+' 1024')\n",
    "\n",
    "        os.system('echo 3108 | sudo -S ./gradlew clean')\n",
    "\n",
    "        for key in clusterPortMap1.keys():\n",
    "            if key>7002:\n",
    "        #         print(key)\n",
    "                print()\n",
    "\n",
    "                for folder in os.listdir('config/'):\n",
    "                    if os.path.isdir('config/'+folder) and 'keys' in folder:\n",
    "                        if os.path.exists('config/'+folder+'/'+'privatekey7001'):\n",
    "                            shutil.copy('config/'+folder+'/'+'privatekey7001','config/'+folder+'/'+'privatekey'+str(key))\n",
    "                            shutil.copy('config/'+folder+'/'+'publickey7001','config/'+folder+'/'+'publickey'+str(key))\n",
    "\n",
    "                print('----------')\n",
    "                print()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "\n",
    "            if os.path.exists('config'+str(i)):\n",
    "                shutil.rmtree('config'+str(i))\n",
    "\n",
    "            os.mkdir('config'+str(i))\n",
    "            os.mkdir('config'+str(i)+'/keysRSA')\n",
    "            os.mkdir('config'+str(i)+'/keysSunEC')\n",
    "            os.mkdir('config'+str(i)+'/keysECDSA')\n",
    "\n",
    "        #     print('config'+str(i)+'/keysECDSA')\n",
    "\n",
    "\n",
    "            shutil.copytree('config/workloads/', 'config'+str(i)+'/workloads')\n",
    "            shutil.copytree('config/keysSSL_TLS/', 'config'+str(i)+'/keysSSL_TLS')\n",
    "        #     print('config/workloads/', 'config'+str(i)+'/workloads')\n",
    "\n",
    "\n",
    "            for file in os.listdir('config/keys/'):\n",
    "\n",
    "                shutil.copy('config/keys/'+file, 'config'+str(i)+'/keysRSA/'+file)\n",
    "                shutil.copy('config/keys/'+file, 'config'+str(i)+'/keysSunEC/'+file)\n",
    "                shutil.copy('config/keys/'+file, 'config'+str(i)+'/keysECDSA/'+file)\n",
    "\n",
    "\n",
    "            shutil.copy('config/system.config', 'config'+str(i)+'/system.config')    \n",
    "            shutil.copy('config/logback.xml', 'config'+str(i)+'/logback.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        clusterIpMap, clusterPortMap1\n",
    "\n",
    "        def find_key_by_value(dictionary, value):\n",
    "            for key, val in dictionary.items():\n",
    "                if val == value:\n",
    "                    return key\n",
    "            # If the value is not found, you might want to handle this case accordingly.\n",
    "            return None\n",
    "\n",
    "\n",
    "        node_info_dict\n",
    "\n",
    "        find_key_by_value(node_info_dict['ServerID'], 4)\n",
    "\n",
    "        for n_cluster in range(n_clusters):\n",
    "\n",
    "            with open('config'+str(n_cluster)+'/hosts.config','w') as file:\n",
    "\n",
    "                for key in clusterIpMap:\n",
    "                    if key < 7000:\n",
    "                        file.writelines(str(key)+' '+clusterIpMap[key]+' '  +clusterPortMap1[key]+' ' +  clusterPortMap2[key]+' '+str(node_info_dict['cluster_id'][find_key_by_value(node_info_dict['ServerID'], key)] )+'\\n')\n",
    "                        print('test: ',str(key)+' '+clusterIpMap[key]+' '  +clusterPortMap1[key]+' ' +  clusterPortMap2[key]+' '+str(node_info_dict['cluster_id'][find_key_by_value(node_info_dict['ServerID'], key)] )+'\\n')\n",
    "                for key in clusterIpMap:\n",
    "                    if key >= 7000:\n",
    "                        file.writelines(str(key)+' '+clusterIpMap[key]+' '+clusterPortMap1[key]+'\\n')\n",
    "                        print('test: ', str(key)+' '+clusterIpMap[key]+' '+clusterPortMap1[key]+'\\n')\n",
    "\n",
    "                file.close()\n",
    "\n",
    "\n",
    "        # for n_cluster in range(n_clusters):\n",
    "\n",
    "        #     with open('config'+str(n_cluster)+'/hosts.config','w') as file:\n",
    "\n",
    "        #         for n_cluster1 in range(n_clusters):\n",
    "\n",
    "        #             for i_replica in range(replica_count):\n",
    "        #     #             file.writelines(str(i_replica)+' '+clusterIpMap[n_cluster*replica_count+i_replica]+' '  +clusterPortMap1[n_cluster*replica_count+i_replica]+' ' +  clusterPortMap2[n_cluster*replica_count+i_replica]+'\\n')\n",
    "        #                 file.writelines(str(n_cluster1*replica_count+i_replica)+' '+clusterIpMap[n_cluster1*replica_count+i_replica]+' '  +clusterPortMap1[n_cluster1*replica_count+i_replica]+' ' +  clusterPortMap2[n_cluster1*replica_count+i_replica]+' '+str(n_cluster1)+'\\n')\n",
    "\n",
    "        #         for iter_ in range(len(ipList) - (n_clusters*replica_count)-nclients):\n",
    "        #             print((n_clusters*replica_count) + iter_)\n",
    "\n",
    "        # #             file.writelines(str((n_clusters*replica_count) + iter_)+' '+clusterIpMap[(n_clusters*replica_count) + iter_]+' '  +clusterPortMap1[(n_clusters*replica_count) + iter_]+' ' +  clusterPortMap2[(n_clusters*replica_count) + iter_]+' '+str(iter_%n_clusters)+'\\n')\n",
    "        #             file.writelines(str((n_clusters*replica_count) + iter_)+' '+clusterIpMap[(n_clusters*replica_count) + iter_]+' '  +clusterPortMap1[(n_clusters*replica_count) + iter_]+' ' +  clusterPortMap2[(n_clusters*replica_count) + iter_]+' '+str(0%n_clusters)+'\\n')\n",
    "\n",
    "        #         for i in range(nclients):\n",
    "        #             file.writelines(str(7001+i)+' '+clusterIpMap[7001+i]+' '+clusterPortMap1[7001+i]+'\\n')\n",
    "\n",
    "\n",
    "        #         file.close()\n",
    "\n",
    "\n",
    "        replica_count\n",
    "\n",
    "        # for n_cluster in range(n_clusters):\n",
    "        #     with open('config'+str(n_cluster)+'/system.config','r') as file:\n",
    "        #         data = file.readlines()\n",
    "        #         f = int(np.ceil((replica_count-1)/3))\n",
    "        #         print('f is',f )\n",
    "\n",
    "        #         for n_line in range(len(data)):\n",
    "        #             if ('system.servers.num' in data[n_line]) and '#' not in data[n_line]:\n",
    "\n",
    "\n",
    "        #                 data[n_line] = 'system.servers.num = '+str(replica_count)\n",
    "        #                 print(data[n_line])\n",
    "\n",
    "        #             if ('system.servers.f' in data[n_line]) and '#' not in data[n_line]:\n",
    "        #                 data[n_line] = 'system.servers.f = '+str(f)\n",
    "        #                 print(data[n_line])\n",
    "\n",
    "\n",
    "        #             if ('system.initial.view' in data[n_line]) and '#' not in data[n_line]:\n",
    "        #                 data[n_line] = 'system.initial.view = '\n",
    "        #                 for iter_view in range(replica_count):\n",
    "        #                     data[n_line] = data[n_line] +str(n_cluster*replica_count+iter_view)+','\n",
    "        # #                     data[n_line] = data[n_line] +str(n_cluster*replica_count+iter_view)+','\n",
    "        #                     print(data[n_line])\n",
    "\n",
    "        #                 data[n_line] = data[n_line][:-1]\n",
    "        #                 print(data[n_line])\n",
    "\n",
    "\n",
    "\n",
    "        #         file.close()\n",
    "\n",
    "        #     with open('config'+str(n_cluster)+'/system.config', 'w') as f:\n",
    "        #         for line in data:\n",
    "        #             f.write(f\"{line}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for n_cluster in range(n_clusters):\n",
    "            with open('config'+str(n_cluster)+'/system.config','r') as file:\n",
    "                data = file.readlines()\n",
    "\n",
    "\n",
    "                nservers = 0\n",
    "                server_id_list = []\n",
    "\n",
    "\n",
    "\n",
    "                for i in node_info_dict['ServerOrClientregion']:\n",
    "                    if node_info_dict['ServerOrClientregion'][i] == 0 and \\\n",
    "                    node_info_dict['cluster_id'][i]  == n_cluster:\n",
    "                        nservers = nservers + 1\n",
    "                        server_id_list.append(node_info_dict['ServerID'][i])\n",
    "\n",
    "                f = int(np.ceil((nservers-1)/3))\n",
    "                print('f is',f )\n",
    "\n",
    "\n",
    "                for n_line in range(len(data)):\n",
    "                    if ('system.servers.num' in data[n_line]) and '#' not in data[n_line]:\n",
    "\n",
    "\n",
    "                        data[n_line] = 'system.servers.num = '+str(nservers)\n",
    "                        print(data[n_line])\n",
    "\n",
    "                    if ('system.servers.f' in data[n_line]) and '#' not in data[n_line]:\n",
    "                        data[n_line] = 'system.servers.f = '+str(f)\n",
    "                        print(data[n_line])\n",
    "\n",
    "\n",
    "                    if ('system.initial.view' in data[n_line]) and '#' not in data[n_line]:\n",
    "                        data[n_line] = 'system.initial.view = '\n",
    "                        for iter_view in server_id_list:\n",
    "                            data[n_line] = data[n_line] +str(iter_view)+','\n",
    "        #                     data[n_line] = data[n_line] +str(n_cluster*replica_count+iter_view)+','\n",
    "                            print(data[n_line])\n",
    "\n",
    "                        data[n_line] = data[n_line][:-1]\n",
    "                        print(data[n_line])\n",
    "\n",
    "\n",
    "\n",
    "                file.close()\n",
    "\n",
    "            with open('config'+str(n_cluster)+'/system.config', 'w') as f:\n",
    "                for line in data:\n",
    "                    f.write(f\"{line}\\n\")\n",
    "\n",
    "\n",
    "        for n_cluster in range(n_clusters):\n",
    "            for i in range(999):\n",
    "\n",
    "                for ncls in  range(1):\n",
    "\n",
    "\n",
    "        #             print('config'+str(n_cluster)+'/keysRSA/'+'publickey7002', \\\n",
    "        #                         'config'+str(n_cluster)+'/keysRSA/'+'publickey'+str(1000+(ncls*100)+i))\n",
    "\n",
    "\n",
    "\n",
    "                    shutil.copy('config'+str(n_cluster)+'/keysRSA/'+'publickey7002', \\\n",
    "                                'config'+str(n_cluster)+'/keysRSA/'+'publickey'+str(1000+(ncls*100)+i))\n",
    "                    shutil.copy('config'+str(n_cluster)+'/keysRSA/'+'privatekey7002', \\\n",
    "                                'config'+str(n_cluster)+'/keysRSA/'+'privatekey'+str(1000+(ncls*100)+i))\n",
    "\n",
    "        #         shutil.copy('config'+str(n_cluster)+'/keysRSA/'+'publickey7002', \\\n",
    "        #                     'config'+str(n_cluster)+'/keysRSA/'+'publickey7002')\n",
    "\n",
    "        #         shutil.copy('config'+str(n_cluster)+'/keysRSA/'+'privatekey7002', \\\n",
    "        #                     'config'+str(n_cluster)+'/keysRSA/'+'privatekey7002')\n",
    "\n",
    "        # os.system('git remote set-url origin https://github.com/tmane002/BftSmart_Final.git')\n",
    "\n",
    "        os.system('git add .; git commit -m \"Working Post Submission: testing\";git push --force origin HEAD:main')\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         time.sleep(30)\n",
    "\n",
    "        # regions = [ 'us-west1-b', 'us-west1-b', 'us-west1-b']\n",
    "        # regions = [ 'us-west1-b']\n",
    "\n",
    "\n",
    "        instance_type = 'e2-small'\n",
    "\n",
    "        df =pd.read_csv('node_info.csv')\n",
    "\n",
    "        node_info_dict = df.to_dict()\n",
    "\n",
    "        node_info_dict\n",
    "\n",
    "        f = open('all_external_ips', \"r\")\n",
    "        data1 = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        data1 = [x for x in data1 if x!='None']\n",
    "\n",
    "        f = open('all_internal_ips', \"r\")\n",
    "        data2 = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        data2 = [x for x in data2 if x!='None']\n",
    "\n",
    "        data2, len(data2)\n",
    "\n",
    "        data = []\n",
    "\n",
    "        skip_instances = 0\n",
    "\n",
    "        for i in range(skip_instances, len(data1)):\n",
    "            if data1[i]!='None':\n",
    "                data.append(data1[i] + '    ' + data2[i])\n",
    "\n",
    "        data, len(data)\n",
    "\n",
    "        for index, item in enumerate(data1):\n",
    "            if 'publicIP' not in node_info_dict.keys():\n",
    "                node_info_dict['publicIP'] = {}\n",
    "\n",
    "\n",
    "            node_info_dict['publicIP'][index] = item \n",
    "\n",
    "\n",
    "        for index, item in enumerate(data2):\n",
    "            if 'privateIP' not in node_info_dict.keys():\n",
    "                node_info_dict['privateIP'] = {}\n",
    "\n",
    "            node_info_dict['privateIP'][index] = item \n",
    "\n",
    "\n",
    "\n",
    "        for index, item in enumerate(data):\n",
    "            if 'publicAndprivateIP' not in node_info_dict.keys():\n",
    "                node_info_dict['publicAndprivateIP'] = {}\n",
    "\n",
    "            node_info_dict['publicAndprivateIP'][index] = item \n",
    "\n",
    "        node_info_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # time.sleep(60)\n",
    "\n",
    "        total_count = 0\n",
    "\n",
    "        for key in node_info_dict['ServerOrClientregion'].keys():\n",
    "            if node_info_dict['ServerOrClientregion'][key] ==0:\n",
    "                total_count = total_count + 1\n",
    "\n",
    "        total_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def getTimeThps(file, flag):\n",
    "\n",
    "            f = open(file, \"r\")\n",
    "            data = f.readlines() \n",
    "\n",
    "            times = []\n",
    "            thputs = []\n",
    "            for line in data:\n",
    "                if 'throughput[ops/s]' in line:\n",
    "                    lineData = (line[13+line.find('max[ops/s])>'):-2])\n",
    "                    print(lineData)\n",
    "\n",
    "                    times.append(lineData.split('|')[0])\n",
    "                    thputs.append(lineData.split('|')[-2])\n",
    "            if (flag): \n",
    "                times.append(float(times[-1])+abs(float(times[-1]) - float(times[-2]) ))\n",
    "                thputs.append(0)\n",
    "\n",
    "            return np.array(times).astype(float), np.array(thputs).astype(float) \n",
    "\n",
    "        with open('all_external_ips') as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "\n",
    "        lines = [x for x in lines if x!='None']\n",
    "        lines, len(lines)\n",
    "\n",
    "        for ip in lines:\n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "\n",
    "                print('ssh -i \"FinalKeys.pem\" ubuntu@ec2-'+str(current[0])+'-'\\\n",
    "                      +str(current[1])+'-'+str(current[2])+'-'+str(current[3])+'.us-west-1.compute.amazonaws.com')\n",
    "\n",
    "        ## Set number of clusters\n",
    "\n",
    "        nclusters = 0\n",
    "\n",
    "        for folder in os.listdir('.'):\n",
    "            if 'config' in folder and folder!='config':\n",
    "                nclusters = nclusters + 1\n",
    "\n",
    "\n",
    "        print(nclusters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nreplicas = int(total_count/nclusters)\n",
    "        \n",
    "        nclients = 0\n",
    "        \n",
    "        for key in node_info_dict['ServerOrClientregion']:\n",
    "            if node_info_dict['ServerOrClientregion'][key]==1:\n",
    "                nclients = nclients + 1\n",
    "        \n",
    "\n",
    "\n",
    "        nodeIps = []\n",
    "        clientIps = []\n",
    "\n",
    "        for i in range(total_count + nclients):\n",
    "            if node_info_dict['ServerOrClientregion'][i] ==0:\n",
    "                nodeIps.append(lines[i])\n",
    "            else:\n",
    "                clientIps.append(lines[i])\n",
    "\n",
    "\n",
    "        # nodeIps = lines[:nclusters* nreplicas]\n",
    "\n",
    "\n",
    "        # no_cluster_yet_nodes = lines[nclusters* nreplicas:-(nclusters)]\n",
    "        no_cluster_yet_nodes = lines[nclusters* nreplicas:-nclients]\n",
    "\n",
    "\n",
    "        experiment = 'bft_mc_'+cfig \n",
    "\n",
    "        # clientIps = lines[-(nclusters):]\n",
    "\n",
    "\n",
    "\n",
    "        # clientIps = lines[-nclients:]\n",
    "\n",
    "\n",
    "\n",
    "        clientIps, no_cluster_yet_nodes\n",
    "\n",
    "\n",
    "\n",
    "        node_info_dict\n",
    "\n",
    "        node_info_dict['region'][0].strip()\n",
    "\n",
    "        ## Functions\n",
    "\n",
    "        def setup(i):\n",
    "\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute scp --zone \"'+str(node_info_dict['region'][i].strip()[1:-1]) +'\"'+' commands.sh'+' resdb-'+f\"{i:03}\"+':/home/tejas/commands.sh'\n",
    "\n",
    "                print(command)\n",
    "                os.system(command)\n",
    "\n",
    "        def initialize(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"sudo sh commands.sh\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "        def git_clone(i):\n",
    "            ip = lines[i]\n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \" sudo git clone https://github.com/tmane002/BftSmart_Final.git\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "        def git_pull(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"git config --global --add safe.directory /home/tejas/BftSmart_Final; cd BftSmart_Final; sudo git pull\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "        def compile_job(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"cd BftSmart_Final; sudo ./gradlew installDist\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "\n",
    "        def clean_job(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "            rm_command = 'sudo rm config/currentView; '\n",
    "            for iter_ in range(nclusters):\n",
    "                rm_command = rm_command + 'sudo rm config'+str(iter_)+'/currentView; '\n",
    "\n",
    "\n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"sudo rm nohup.out; cd BftSmart_Final; '+rm_command+'\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "        def clean_all(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "            rm_command = 'sudo rm -r BftSmart_Final; sudo rm nohup.out;sudo rm nohup_client.out;'\n",
    "\n",
    "\n",
    "\n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"sudo rm nohup.out; '+rm_command+'\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #     if ip!='None' and( ip in no_cluster_yet_nodes):\n",
    "\n",
    "        #         current = (ip.split('.'))\n",
    "        #         command = 'ssh  -o StrictHostKeyChecking=no -i /home/tejas/Documents/FKA.pem '+'ubuntu@ec2-'+str(current[0])+'-'\\\n",
    "        #               +str(current[1])+'-'+str(current[2])+'-'+str(current[3])+'.ap-south-1.compute.amazonaws.com -T \"cd BftSmart_Final; sudo nohup ./runscripts/startReplicaYCSB.sh '+str(i)+' >../nohup.out 2>&1 &\"'\n",
    "\n",
    "\n",
    "        #         os.system(command)        \n",
    "        # #         print(command)\n",
    "\n",
    "        def check_node(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"tail -n 1000 nohup.out\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "        #         print(command)\n",
    "\n",
    "\n",
    "        def run_basic_client(i):\n",
    "            cmd_arg = ''\n",
    "\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==1:\n",
    "\n",
    "                current = (ip.split('.'))\n",
    "\n",
    "\n",
    "                cmd_arg = str(node_info_dict['clientID'][i])\n",
    "\n",
    "\n",
    "\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"cd BftSmart_Final; sudo nohup ./runscripts/ycsbClient.sh '+str(cmd_arg)+' >../nohup_client.out 2>&1 &\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "        def kill_java(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "            if ip!='None':\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"cd BftSmart_Final; sudo killall java; sudo killall nohup; sudo killall hotstuff-app; sudo killall hotstuff-client;\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "\n",
    "        def kill_clients(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None' and ip in clientIps:\n",
    "                current = (ip.split('.'))\n",
    "                command = 'ssh -o StrictHostKeyChecking=no -i /home/tejas/Documents/'+node_info_dict['key_file'][i].strip()[1:-1]+' '+'ubuntu@ec2-'+str(current[0])+'-'\\\n",
    "                      +str(current[1])+'-'+str(current[2])+'-'+str(current[3])+'.'+node_info_dict['region'][i].strip()[1:-1]+'.compute.amazonaws.com -T \"cd BftSmart_Final; sudo killall java; sudo killall nohup\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "        def run_server_node_check(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==0:\n",
    "\n",
    "                current = (ip.split('.'))\n",
    "                command = 'ssh  -o StrictHostKeyChecking=no -i /home/tejas/Documents/'+node_info_dict['key_file'][i].strip()[1:-1]+' '+'ubuntu@ec2-'+str(current[0])+'-'\\\n",
    "                      +str(current[1])+'-'+str(current[2])+'-'+str(current[3])+'.'+node_info_dict['region'][i].strip()[1:-1]+'.compute.amazonaws.com -T \"cd BftSmart_Final; sudo nohup ./runscripts/startReplicaYCSB.sh '+str(i)+' >../nohup.out 2>&1 &\"'\n",
    "\n",
    "\n",
    "                print(command)\n",
    "\n",
    "\n",
    "\n",
    "        # for i in range(len(lines)):\n",
    "        #     run_server_node_check(i)\n",
    "\n",
    "        def run_basic_client_check(i):\n",
    "            cmd_arg = ''\n",
    "\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==1:\n",
    "\n",
    "                cmd_arg = str(node_info_dict['clientID'][i])\n",
    "\n",
    "\n",
    "        #         print(i, cmd_arg)\n",
    "\n",
    "                current = (ip.split('.'))\n",
    "                command = 'ssh  -o StrictHostKeyChecking=no -i /home/tejas/Documents/'+node_info_dict['key_file'][i].strip()[1:-1]+' '+'ubuntu@ec2-'+str(current[0])+'-'\\\n",
    "                      +str(current[1])+'-'+str(current[2])+'-'+str(current[3])+'.'+node_info_dict['region'][i].strip()[1:-1]+'.compute.amazonaws.com \"cd BftSmart_Final; sudo nohup ./runscripts/ycsbClient.sh '+str(cmd_arg)+' >../nohup.out 2>&1 &\"'\n",
    "\n",
    "\n",
    "                print(command)\n",
    "\n",
    "\n",
    "\n",
    "        ## First Time Setup\n",
    "\n",
    "        lines, len(lines)\n",
    "\n",
    "        # for i in range(10):\n",
    "        #     setup(i)\n",
    "\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(setup)(i) for i in range(len(lines)))\n",
    "        print(results)  \n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(initialize)(i) for i in range(len(lines)))\n",
    "        print(results)  \n",
    "\n",
    "        # ## GIT Clone/Pull\n",
    "\n",
    "\n",
    "\n",
    "        # # results = Parallel(n_jobs=60)(delayed(clean_all)(i) for i in range(len(lines)))\n",
    "        # results = Parallel(n_jobs=60)(delayed(git_pull)(i) for i in range(len(lines)))\n",
    "        # # results = Parallel(n_jobs=60)(delayed(git_clone)(i) for i in range(len(lines)))\n",
    "\n",
    "\n",
    "        # print(results)  \n",
    "\n",
    "        # ## Compile Job\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(compile_job)(i) for i in range(len(lines)))\n",
    "        print(results)  \n",
    "\n",
    "        # ## CLEAN SERVERS\n",
    "\n",
    "        # results = Parallel(n_jobs=60)(delayed(clean_job)(i) for i in range(len(lines)))\n",
    "        # # results = Parallel(n_jobs=60)(delayed(clean_all)(i) for i in range(len(lines)))\n",
    "\n",
    "        # print(results)  \n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(kill_java)(i) for i in range(len(lines)))\n",
    "\n",
    "        def run_server_node(i):\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "        #     if ip!='None' and( ip in nodeIps or ip in no_cluster_yet_nodes):\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==0:\n",
    "\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute ssh --zone \"'+str(node_info_dict['region'][i].strip()[1:-1])+'\" \"resdb-'+f\"{i:03}\"+'\" --project \"ucr-ursa-major-lesani-lab\" --command \"cd BftSmart_Final; sudo nohup ./runscripts/startReplicaYCSB.sh '+str(node_info_dict['ServerID'][i])+' >../nohup.out 2>&1 &\"'\n",
    "\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "\n",
    "        # for i in node_info_dict['publicIP']:\n",
    "        #     run_server_node(i)\n",
    "\n",
    "        ## RUN SERVERS\n",
    "\n",
    "        # results = Parallel(n_jobs=60)(delayed(run_server_node)(i) for i in range(len(lines)))\n",
    "        # print(results)  \n",
    "\n",
    "        ### CHECK NODE RESULT\n",
    "\n",
    "        # check_node(0)\n",
    "\n",
    "        # ## Run basic client\n",
    "\n",
    "        # # time.sleep(20)\n",
    "        # results = Parallel(n_jobs=60)(delayed(run_basic_client)(i) for i in range(len(lines)))\n",
    "        # print(results)  \n",
    "\n",
    "        # check_node(0)\n",
    "\n",
    "        # time.sleep(60)\n",
    "\n",
    "        # results = Parallel(n_jobs=60)(delayed(kill_java)(i) for i in range(len(lines)))\n",
    "\n",
    "        # results = Parallel(n_jobs=60)(delayed(clean_job)(i) for i in range(len(lines)))\n",
    "\n",
    "        ## Main Job\n",
    "\n",
    "        # os.system('git add .; git commit -m \"test\";git push')\n",
    "\n",
    "\n",
    "        # time.sleep(60)\n",
    "\n",
    "        os.system('git add .; git commit -m \"Working with modified ClusterInfo\";git push --force origin HEAD:main')\n",
    "\n",
    "# if 2>1:\n",
    "#     if 2>1:\n",
    "        \n",
    "        #     %%time\n",
    "\n",
    "\n",
    "        # results = Parallel(n_jobs=60)(delayed(clean_all)(i) for i in range(len(lines)))\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(kill_java)(i) for i in range(len(lines)))\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(git_pull)(i) for i in range(len(lines)))\n",
    "        # results = Parallel(n_jobs=60)(delayed(git_clone)(i) for i in range(len(lines)))\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(compile_job)(i) for i in range(len(lines)))\n",
    "        # print(results) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(clean_job)(i) for i in range(len(lines)))\n",
    "        # results = Parallel(n_jobs=60)(delayed(clean_all)(i) for i in range(len(lines)))\n",
    "\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(run_server_node)(i) for i in range(len(lines)))\n",
    "        # print(results)  \n",
    "\n",
    "\n",
    "        print('XXXXXXXX Started Servers XXXXXXXXXXXX')\n",
    "\n",
    "        time.sleep(70)\n",
    "        \n",
    "\n",
    "        check_node(7)\n",
    "\n",
    "        print('XXXXXXXX Started Clients XXXXXXXXXXXX')\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(run_basic_client)(i) for i in range(len(lines)))\n",
    "\n",
    "\n",
    "\n",
    "        time.sleep(100)\n",
    "#         results = Parallel(n_jobs=60)(delayed(kill_java)(i) for i in [0])\n",
    "        time.sleep(200)\n",
    "\n",
    "        results = Parallel(n_jobs=60)(delayed(kill_java)(i) for i in range(len(lines)))\n",
    "\n",
    "        check_node(0)\n",
    "\n",
    "        if not os.path.exists('../Experiments/'+experiment):\n",
    "            os.mkdir('../Experiments/'+experiment)\n",
    "\n",
    "        os.system('cd ../Experiments/'+experiment+';rm *;cd ../; rm '+experiment+'.png')\n",
    "\n",
    "\n",
    "\n",
    "        for i in node_info_dict['publicIP']:\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==0:\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute scp --zone \"'+str(node_info_dict['region'][i].strip()[1:-1]) +'\"'+' resdb-'+f\"{i:03}\"+':/home/tejas/nohup.out ../Experiments/'+experiment+'/nohup_c'+str(nreplicas)+'_'+str(node_info_dict['ServerID'][i])+'.out'\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "                break;\n",
    "                \n",
    "                \n",
    "\n",
    "        for i in node_info_dict['publicIP']:\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "\n",
    "\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==0:\n",
    "                print('client copying id= ',i)\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute scp --zone \"'+str(node_info_dict['region'][i].strip()[1:-1]) +'\"'+' resdb-'+f\"{i:03}\"+':/home/tejas/BftSmart_Final/data.json ../Experiments/'+experiment+'/nohup_times_'+str(i)+'.out'\n",
    "                print(command)\n",
    "                os.system(command)\n",
    "                \n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in node_info_dict['publicIP']:\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "\n",
    "\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==1:\n",
    "                print('client copying id= ',i)\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute scp --zone \"'+str(node_info_dict['region'][i].strip()[1:-1]) +'\"'+' resdb-'+f\"{i:03}\"+':/home/tejas/nohup_client.out ../Experiments/'+experiment+'/nohup_client_'+str(node_info_dict['clientID'][i])+'.out'\n",
    "                print(command)\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "        for i in node_info_dict['publicIP']:\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "\n",
    "            print(i)\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==1:\n",
    "                print('client copying id= ',i)\n",
    "\n",
    "\n",
    "        node_info_dict\n",
    "\n",
    "        clientIps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def getTimesThputs(file):\n",
    "            f = open(file, \"r\")\n",
    "            data = f.readlines() \n",
    "            times = []\n",
    "            thputs = []\n",
    "            latencies = []\n",
    "            for line in data:\n",
    "        #         print(line)\n",
    "                if not line.startswith('--') and 'current ops/sec; ' in line and 'AverageLatency(us)=' in line and not 'JVM' in line:\n",
    "\n",
    "        #         print(line)\n",
    "                    times.append(line.split('sec:')[0].strip())\n",
    "                    thputs.append(line.split(';')[1].split('current')[0].strip())\n",
    "                \n",
    "                \n",
    "                    read_lat = '0'\n",
    "                    write_lat = '0'\n",
    "                    \n",
    "                    if ('READ AverageLatency' in line):\n",
    "                        \n",
    "                        print(line)\n",
    "\n",
    "                        read_lat = line.split('READ AverageLatency(us)=')[1].split(']')[0].strip()\n",
    "                        \n",
    "                        \n",
    "                    if ('UPDATE AverageLatency' in line):                    \n",
    "                        \n",
    "                        write_lat = line.split('UPDATE AverageLatency(us)=')[1].split(']')[0].strip()\n",
    "\n",
    "\n",
    "                    if (('READ AverageLatency' not in line) and ('UPDATE AverageLatency' not in line)):\n",
    "                        latencies.append(line.split('=')[1].split(']')[0].strip())\n",
    "                    else:\n",
    "                        read_frac = 0\n",
    "                        write_frac = 0\n",
    "                        \n",
    "                        if float(read_lat) > 0:\n",
    "                            read_frac = 0.85\n",
    "                            \n",
    "                        if float(write_lat) > 0:\n",
    "                            write_frac = 0.15\n",
    "                            \n",
    "#                         print(line, write_frac, read_frac, float(read_lat), float(write_lat))\n",
    "                        \n",
    "                        lat = str( (write_frac * float(write_lat) +\\\n",
    "                                    read_frac*float(read_lat))/(write_frac+read_frac)\\\n",
    "                                 )\n",
    "                        latencies.append(lat)\n",
    "\n",
    "                    print(line,latencies[-1],thputs[-1],times[-1])\n",
    "\n",
    "            return np.array(times).astype(float), np.array(thputs).astype(float), np.array(latencies).astype(float)/1e6  \n",
    "\n",
    "\n",
    "        times_thputsDict = {}\n",
    "        times_latsDict = {}\n",
    "\n",
    "\n",
    "#         for ip in clientIps[:1]:    \n",
    "#             i = clientIps.index(ip)\n",
    "\n",
    "#             times ,thputs, lats = getTimesThputs('../Experiments/'+experiment+'/nohup_client_'+str(i)+'.out')\n",
    "\n",
    "#             print(times, thputs)\n",
    "#             for i in range(len(times)):\n",
    "#                 times_thputsDict[times[i]] = thputs[i]\n",
    "#                 times_latsDict[times[i]] = lats[i]\n",
    "\n",
    "\n",
    "#         for ip in clientIps[1:]:    \n",
    "#             i = clientIps.index(ip)\n",
    "\n",
    "#             times ,thputs, lats = getTimesThputs('../Experiments/'+experiment+'/nohup_client_'+str(i)+'.out')\n",
    "\n",
    "\n",
    "#             for i in range(len(times)):\n",
    "\n",
    "#                 if times[i] in times_thputsDict.keys():\n",
    "#                     times_thputsDict[times[i]] += thputs[i]\n",
    "\n",
    "#                 if times[i] in times_latsDict.keys():\n",
    "#                     times_latsDict[times[i]] += lats[i]\n",
    "\n",
    "\n",
    "#         times_thputsDict\n",
    "\n",
    "\n",
    "\n",
    "#         PIK = '../Experiments/'+experiment+\"/pickle.dat\"\n",
    "\n",
    "#         data = [times_thputsDict, times_latsDict]\n",
    "\n",
    "#         with open(PIK, \"wb\") as f:\n",
    "#             pickle.dump(data, f)\n",
    "\n",
    "#         experiment\n",
    "\n",
    "#         # experiment = 'TestRun2_8_clusters_2'\n",
    "#         # PIK = '../Experiments/'+experiment+\"/pickle.dat\"\n",
    "\n",
    "#         data2 = []\n",
    "        \n",
    "#         with open(PIK, \"rb\") as f:\n",
    "#             data2 =  pickle.load(f)\n",
    "\n",
    "\n",
    "#         dict1 = data2[0]\n",
    "#         dict2 = data2[1]\n",
    "\n",
    "\n",
    "\n",
    "#         times1 = np.array(list(dict1.keys()))\n",
    "#         thputs = np.array(list(dict1.values()))\n",
    "\n",
    "#         times2 = np.array(list(dict2.keys()))\n",
    "#         lats = np.array(list(dict2.values()))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "#         times_new = [x for x in range(1+int(times1[-1]))]\n",
    "#         thputs_new = [0 for x in range(1+int(times1[-1]))]\n",
    "\n",
    "#         for idx, t in enumerate(times1):\n",
    "#             thputs_new[int(t)] = thputs[idx]\n",
    "\n",
    "    \n",
    "\n",
    "#         pl.figure(figsize = (12,8))\n",
    "#         pl.rcParams.update({'font.size': 17})\n",
    "#         pl.plot(times_new[:], thputs_new[:], '-o', label='BfTSmart-MC')\n",
    "\n",
    "\n",
    "#         pl.title(r'Throughput')\n",
    "\n",
    "\n",
    "#         pl.xlabel('Time (s)')\n",
    "#         pl.ylabel('Throughput (Txn/s)')\n",
    "#         pl.legend()\n",
    "#         pl.savefig('../Experiments/'+experiment+'/out1.png', dpi = 150)\n",
    "#         pl.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         pl.figure(figsize = (12,8))\n",
    "#         pl.rcParams.update({'font.size': 17})\n",
    "#         pl.plot(times1[:], lats[:]/ len(clientIps), '-o', label='BfTSmart-MC')\n",
    "\n",
    "\n",
    "#         pl.title(r'Latency')\n",
    "\n",
    "\n",
    "#         pl.xlabel('Time (s)')\n",
    "#         pl.ylabel('Latency (Txn/s)')\n",
    "#         pl.legend()\n",
    "#         pl.savefig('../Experiments/'+experiment+'/out2.png', dpi = 150)\n",
    "#         pl.show()\n",
    "\n",
    "#         times1, lats\n",
    "\n",
    "#         lats, np.average(lats[-85:-5])/len(clientIps)\n",
    "\n",
    "#         np.sum(thputs),  np.average(thputs[-85:-5])\n",
    "\n",
    "#         thputs\n",
    "\n",
    "#         np.average(thputs[60:80]), np.average(lats[60:80])/nclusters, np.average(thputs[-35:-5]), np.average(lats[-35:-5])\n",
    "\n",
    "#         # np.average(lats[-50:]), np.average(thputs[-50:]) # (0.0542783668, 166.87759999999997)\n",
    "\n",
    "#         np.sum((thputs[:180]))\n",
    "\n",
    "#         np.sum((thputs[:180]))\n",
    "        \n",
    "        \n",
    "        for i in node_info_dict['publicIP']:\n",
    "            ip = node_info_dict['publicIP'][i] \n",
    "\n",
    "\n",
    "            if ip!='None' and node_info_dict['ServerOrClientregion'][i]==0:\n",
    "                current = (ip.split('.'))\n",
    "                command = 'gcloud compute scp --zone \"'+str(node_info_dict['region'][i].strip()[1:-1]) +'\"'+' resdb-'+f\"{i:03}\"+':/home/tejas/nohup.out ../Experiments/'+experiment+'/nohup_c'+str(nreplicas)+'_'+str(node_info_dict['ServerID'][i])+'.out'\n",
    "\n",
    "                os.system(command)\n",
    "\n",
    "                break;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        os.system('gcloud compute instances delete --zone=europe-west3-c --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "        os.system('gcloud compute instances delete --zone=asia-south1-c --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "        os.system('gcloud compute instances delete --zone=us-west1-b --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "\n",
    "    except:\n",
    "        \n",
    "        os.system('gcloud compute instances delete --zone=europe-west3-c --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "        os.system('gcloud compute instances delete --zone=asia-south1-c --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "        os.system('gcloud compute instances delete --zone=us-west1-b --quiet $(gcloud compute instances list --format=\"value(name)\")')\n",
    "        \n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617cbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98148602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
